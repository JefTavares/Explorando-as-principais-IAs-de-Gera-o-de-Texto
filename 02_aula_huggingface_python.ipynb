{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Rodando localmente",
   "id": "4eddb4f714119b12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Carregando o modelo",
   "id": "c292a16ccd50dcac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:11:17.179024Z",
     "start_time": "2024-12-26T20:10:59.085549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# Pega o nome do modelo que está lá no HaggingFace\n",
    "model_name = 'Qwen/Qwen2-1.5B-Instruct' #gpt2 para testar modelos mais leves\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "744534ee8b91be0d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Utilizado pipeline para geração de texto",
   "id": "8417ca34055fddf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:15:04.282977Z",
     "start_time": "2024-12-26T20:14:57.918119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gerador = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "resultado = gerador('Era uma vez', max_length=25) #Pedindo para completar o texto com até 25 tokens\n",
    "print(resultado)"
   ],
   "id": "eae6c63624e2270f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Era uma vez um pequeno reino chamado Cemil, que era famoso por sua beleza e r'}]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:31:06.307784Z",
     "start_time": "2024-12-26T20:31:06.296108Z"
    }
   },
   "cell_type": "code",
   "source": "resultado[0]['generated_text']",
   "id": "3095b84b9d0f696d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Era uma vez um pequeno reino chamado Cemil, que era famoso por sua beleza e r'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gerando texto manualmente",
   "id": "52b02119c00c8c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:34:54.878095Z",
     "start_time": "2024-12-26T20:34:54.840931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids = tokenizer.encode('Era uma vez', return_tensors='pt')\n",
    "input_ids"
   ],
   "id": "a9792740d6836b7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   36,   956, 10608, 20563]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:39:17.875038Z",
     "start_time": "2024-12-26T20:39:13.175180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = model.generate(input_ids, max_length=25)\n",
    "output"
   ],
   "id": "607697ac5037b3aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   36,   956, 10608, 20563,  4443, 80672, 11790, 41665, 33709,  2123,\n",
       "           619,   567,   318,    13,   506,   281, 21715, 11385, 15886,   321,\n",
       "           384,  1079, 43315,    11,  9243]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:43:52.975286Z",
     "start_time": "2024-12-26T20:43:52.956316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resultado = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(resultado)"
   ],
   "id": "72c763a9b943c167",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Era uma vez um pequeno país chamado Jardim. O povo era gentil e amável, mas\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Criando uma estrutura de conversação",
   "id": "7676e088f8494b61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:47:57.524444Z",
     "start_time": "2024-12-26T20:47:57.497353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [{'role':'user', 'content':'Olá'}] # user fala Olá\n",
    "text = tokenizer.apply_chat_template(messages,tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer([text], return_tensors='pt')\n",
    "inputs"
   ],
   "id": "2164a8dfeebd6617",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
       "         151645,    198, 151644,    872,    198,  42719,   1953, 151645,    198,\n",
       "         151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:48:21.184257Z",
     "start_time": "2024-12-26T20:48:20.108621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(inputs.input_ids, max_length=25, do_sample=True)\n",
    "resultado = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(resultado)"
   ],
   "id": "1bf015d5070e4437",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Olá\n",
      "assistant\n",
      "Olá! Como\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Criando um pequeno loop de conversa",
   "id": "4b8a2c8585ba5e61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mensagens = []\n",
    "for i in range(3):\n",
    "    messages.append({'role':'user', 'content':input('Fale algo com o assitente: ')})\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer([text], return_tensors='pt')\n",
    "    outputs = model.generate(inputs.input_ids, max_length=500, do_sample=True)\n",
    "    resultado = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    resposta_assist = resultado.split('assistant')[-1].strip('/n')\n",
    "    print(resposta_assist)\n",
    "    messages.append({'role':'assistant', 'content':resposta_assist})"
   ],
   "id": "34e7351c7a8a9a91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
